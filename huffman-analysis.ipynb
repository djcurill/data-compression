{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048ae216",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Code Design Test: Data Compression Design\n",
    "Design an algorithm that will compress a given data buffer of bytes. Please describe your design and submit an\n",
    "implementation in Python.\n",
    "Your submission will be judged based on\n",
    "- The number of bytes your output uses if saved to file\n",
    "- Run time\n",
    "- Scalability\n",
    "- Maintainability\n",
    "- Testability\n",
    "\n",
    "**Assumptions**\n",
    "1. data is an array of bytes. Each byte will contain a number from 0 to 127 (0x00 to 0x7F). It is common\n",
    "for the data in the buffer to have the same value repeated in the series.\n",
    "2. The compressed data will need to be decompressable. Please ensure that your algorithm allows for a\n",
    "decompression algorithm to return the buffer to its previous form.\n",
    "\n",
    "**Example**\n",
    "```python\n",
    "data = bytes([0x03, 0x74, 0x04, 0x04, 0x04, 0x35, 0x35, 0x64,\n",
    "0x64, 0x64, 0x64, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
    "0x56, 0x45, 0x56, 0x56, 0x56, 0x09, 0x09, 0x09])\n",
    "compressed_bytes = byte_compress(data)\n",
    "```\n",
    "\n",
    "## Algorithm Design\n",
    "\n",
    "There are two important properties that can be leveraged to reduce the size of the data:\n",
    "1. The sequence of bytes consist of numbers that range from 0 - 127.\n",
    "2. Numbers tend to repeat themselves which suggests the distribution of integers will likely be skewed (i.e. not uniform). \n",
    "\n",
    "Two popular algorithms can be used to compress the data. Each will have their tradeoffs.\n",
    "1. Fixed length encoding \n",
    "2. Huffmaan enconding\n",
    "\n",
    "### Choosing an Algorithm\n",
    "#### Fixed Length Enconding\n",
    "**Pros**\n",
    "* one\n",
    "* two\n",
    "\n",
    "**Cons**\n",
    "* \n",
    "*\n",
    "\n",
    "#### Huffman Encoding\n",
    "**Pros**\n",
    "* one \n",
    "* two\n",
    "\n",
    "**Cons**\n",
    "* one\n",
    "* two\n",
    "\n",
    "The huffman enconding technique offers more flexibility and will likely outperform the Fixed length encoding method should the data be much more likely to be skewed. This algorithm will not perform well if the distribution of data turns out to be uniform (i.e. a high degree of entropy). \n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "Huffman enconding requires the construction of Huffman tree that arranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da5f48ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "bitarray index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m final_bits \u001b[38;5;241m=\u001b[39m compress_bytes(data, encoder)\n\u001b[1;32m     17\u001b[0m final_bytes \u001b[38;5;241m=\u001b[39m final_bits\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m---> 19\u001b[0m decompressed_data \u001b[38;5;241m=\u001b[39m \u001b[43mdecompress_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m size_before \u001b[38;5;241m=\u001b[39m number_of_bits(original_bytes)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize before compression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_before\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/huffman-compression/src/decompress.py:18\u001b[0m, in \u001b[0;36mdecompress_bytes\u001b[0;34m(data, decoder)\u001b[0m\n\u001b[1;32m     16\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bits):\n\u001b[0;32m---> 18\u001b[0m     symbol, pos \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(symbol)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/code/huffman-compression/src/lossless/decoders/huffman_decoder.py:23\u001b[0m, in \u001b[0;36mHuffmanDecoder.__call__\u001b[0;34m(self, bits, start)\u001b[0m\n\u001b[1;32m     21\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node\u001b[38;5;241m.\u001b[39mis_leaf_node():\n\u001b[0;32m---> 23\u001b[0m     bit \u001b[38;5;241m=\u001b[39m \u001b[43mbits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m     node \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;28;01mif\u001b[39;00m bit \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m node\u001b[38;5;241m.\u001b[39mright\n\u001b[1;32m     25\u001b[0m     pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: bitarray index out of range"
     ]
    }
   ],
   "source": [
    "from src.lossless.encoders.hoffman_encoder import HuffmanEncoder\n",
    "from src.lossless.decoders.huffman_decoder import HuffmanDecoder\n",
    "from src.core.dist import Dist\n",
    "from src.core.tree import HoffmanTree\n",
    "from src.compress import compress_bytes\n",
    "from src.decompress import decompress_bytes\n",
    "from src.utils import generate_random_data, number_of_bits\n",
    "from bitarray import bitarray\n",
    "\n",
    "data = generate_random_data(1000, p=0.1)\n",
    "original_bytes = bytes(data)\n",
    "dist = Dist(data)\n",
    "tree = HoffmanTree(dist)\n",
    "encoder = HuffmanEncoder(tree=tree)\n",
    "decoder = HuffmanDecoder(tree=tree)\n",
    "final_bits = compress_bytes(data, encoder)\n",
    "final_bytes = final_bits.tobytes()\n",
    "\n",
    "decompressed_data = decompress_bytes(final_bytes, decoder)\n",
    "size_before = number_of_bits(original_bytes)\n",
    "print(f\"Size before compression: {size_before}\")\n",
    "\n",
    "size_after = number_of_bits(final_bytes)\n",
    "print(f\"Size after compression: {size_after}\")\n",
    "\n",
    "\n",
    "\n",
    "if data == decompressed_data:\n",
    "    print(\"Success: Decompression returned origin result\")\n",
    "else:\n",
    "    print(\"Error: Original bytes do not equal decompressed bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d81feb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = final_bits\n",
    "b = final_bits.tobytes()\n",
    "c = bitarray(endian=\"big\")\n",
    "c.frombytes(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f5171a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfbe0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(n:int) -> bitarray:\n",
    "    if n <= 1:\n",
    "        return bitarray(str(n))\n",
    "    return to_binary(n // 2) + bitarray(str(n % 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecc672f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitarray('1010')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_binary(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de53e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bitarray()\n",
    "a.frombytes(bytes(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f677e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitarray('00000000')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = HoffmanTree(dist)\n",
    "encoder = HuffmanEncoder(tree=tree)\n",
    "decoder = HuffmanDecoder(tree=tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bytes = compress_bytes(data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97859bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bitarray()\n",
    "b.frombytes(final_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3] == [1,3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decompress_bytes(final_bytes, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1852ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = bitarray()\n",
    "before.frombytes(original_bytes)\n",
    "\n",
    "after = bitarray()\n",
    "after.frombytes(final_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339782b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ff6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07920a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitarray(int.from_bytes(b.tobytes(), 'big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bytes([0x03, 0x74, 0x04, 0x04, 0x04, 0x35, 0x35, 0x64,\n",
    "0x64, 0x64, 0x64, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
    "0x56, 0x45, 0x56, 0x56, 0x56, 0x09, 0x09, 0x09])\n",
    "b = bitarray()\n",
    "b.frombytes(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63198dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
